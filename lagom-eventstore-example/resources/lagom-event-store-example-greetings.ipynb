{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lagom-Project EventStore example\n",
    "\n",
    "This notebook is part of the Lagom-event-store-example application. The Lagom code generates data that is stored into IBM EventStore and then you may read and analyse the data using this notebook. See the repository [README.md](https://github.com/lagom/ibm-integration-examples/tree/master/lagom-eventstore-example) for more details.\n",
    "\n",
    "This notebook uses the Scala API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Query the table](#query-table)<br>\n",
    "   1.1 [Connect to Project EventStore](#connect-to-es-two)<br>\n",
    "   1.2 [Create sqlContext using EventSession](#create-sqlContext)<br>\n",
    "   1.3 [Prepare a DataFrame for the query](#prepare-DataFrame)<br>\n",
    "   1.4 [Run the SQL query](#run-query)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query-table\"></a>\n",
    "## 1. Query the table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"connect-to-es-two\"></a>\n",
    "### 1.1 Connect to Project EventStore \n",
    "\n",
    "To establish a connection to IBM Project EventStore, you need connection endpoints. Use the configuration reader to provide a set of APIs for Project EventStore connection and configuration. \n",
    "\n",
    "`// ConfigurationReader.setConnectionEndpoints(\"<HostName>:<PortNumber>\")` \n",
    "\n",
    "You can also specify multiple connection endpoints by providing a connection string that contains comma-separated list of HostName:PortNumber pairs.\n",
    "\n",
    "`//ConfigurationReader.setConnectionEndpoints(\"<HostName1>:<PortNumber1>,<HostName2>:<PortNumber2>,<Hostname3>:<PortNumber3>\")` \n",
    "\n",
    "Using the configuration reader API, set up the userID and password that will be used to connect to Project EventStore.\n",
    "\n",
    "If you are using Project EventStore on a local machine, use you public IP insteads of `localhost`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import com.ibm.event.common.ConfigurationReader\n",
    "ConfigurationReader.setConnectionEndpoints(\"192.168.1.33:5555\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create-sqlContext\"></a>\n",
    "### 1.2 Create sqlContext using EventSession\n",
    "\n",
    "To run a Spark SQL query, you need to establish a Project EventStore Spark session using sqlContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import java.io.File\n",
    "import com.ibm.event.oltp.EventContext\n",
    "import org.apache.log4j.{Level, LogManager, Logger}\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.sql.ibm.event.EventSession\n",
    "\n",
    "val sqlContext = new EventSession(spark.sparkContext, \"GreetingsDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare-DataFrame\"></a>\n",
    "### 1.3 Prepare a DataFrame for the query \n",
    "The following API provides a DataFrame that holds the query results on the Project EventStore table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: java.lang.Exception\n",
       "Message: Could not find GreetingsDB\n",
       "StackTrace:   at com.ibm.event.coordination.ZkCoordinatorFromMessage.getDatabaseOption(ZkCoordinator.scala:193)\n",
       "  at com.ibm.event.coordination.ZkCoordinatorFromMessage.getDatabase(ZkCoordinator.scala:209)\n",
       "  at org.apache.spark.sql.ibm.event.EventSession.database$lzycompute(EventSession.scala:56)\n",
       "  at org.apache.spark.sql.ibm.event.EventSession.database(EventSession.scala:56)\n",
       "  at org.apache.spark.sql.ibm.event.EventSession.loadEventTable(EventSession.scala:142)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  val TABLE_NAME = \"Greetings\";\n",
    "  val table = sqlContext.loadEventTable(TABLE_NAME)\n",
    "  table.registerTempTable(TABLE_NAME)\n",
    "  val resultSet = sqlContext.sql(\"select count(*) as totalRows from \" + TABLE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"run-query\"></a>\n",
    "### 1.4 Run the SQL query\n",
    "Now you can materialize the dataframe associated with the sql query by using either show() or pretty print %%dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: lastException: Throwable = null\n",
       "<console>:26: error: not found: value resultSet\n",
       "       resultSet.show()\n",
       "       ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultSet.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>totalRows</th></tr><tr><td>1000000</td></tr></table>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%dataframe resultSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* [Lagom - IBM integration example projects](https://github.com/lagom/ibm-integration-examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; 2016-2017 Lightbend Inc. <https://www.lightbend.com>.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
